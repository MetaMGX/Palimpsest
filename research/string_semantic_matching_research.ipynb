{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# String Semantic Matching Research\n\n## Overview\nThis notebook investigates string semantic matching techniques using sentence transformers for the Palimpsest project.\n\n## Research Goals\n1. Evaluate semantic similarity calculation methods\n2. Compare performance of different approaches\n3. Establish best practices for large-scale text processing"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport time\nimport pandas as pd\n\n# Load sentence transformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Experiment 1: Basic Semantic Similarity\nImplementing and testing basic semantic similarity using Sentence Transformers"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Sample text data for experiments\ntext_pairs = [\n    (\"The cat sat on the mat\", \"A feline rested on the rug\"),\n    (\"She walked to the store\", \"The woman went shopping\"),\n    (\"The book was interesting\", \"The novel was engaging\"),\n    (\"He drove the car fast\", \"The vehicle was speeding\"),\n    (\"The sun is bright today\", \"It's a sunny day outside\")\n]\n\ndef semantic_similarity_transformer(text1, text2, model):\n    embedding1 = model.encode([text1])[0]\n    embedding2 = model.encode([text2])[0]\n    return np.dot(embedding1, embedding2)/(np.linalg.norm(embedding1)*np.linalg.norm(embedding2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Experiment 2: Batch Processing\nImplementing batch processing for improved efficiency"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def batch_semantic_similarity(text_pairs, model):\n    sentences = [t[0] for t in text_pairs] + [t[1] for t in text_pairs]\n    embeddings = model.encode(sentences)\n    n = len(text_pairs)\n    embeddings1 = embeddings[:n]\n    embeddings2 = embeddings[n:]\n    similarities = [cosine_similarity([emb1], [emb2])[0][0] \n                   for emb1, emb2 in zip(embeddings1, embeddings2)]\n    return similarities"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Performance Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Run experiments and measure performance\nprint(\"Running individual similarity calculations...\")\nstart_time = time.time()\nindividual_results = []\nfor text1, text2 in text_pairs:\n    similarity = semantic_similarity_transformer(text1, text2, model)\n    individual_results.append(similarity)\nindividual_time = time.time() - start_time\n\nprint(\"\\nRunning batch similarity calculations...\")\nstart_time = time.time()\nbatch_results = batch_semantic_similarity(text_pairs, model)\nbatch_time = time.time() - start_time\n\n# Create results DataFrame\nresults_df = pd.DataFrame({\n    'Text Pair': [f\"{t1} || {t2}\" for t1, t2 in text_pairs],\n    'Individual Similarity': individual_results,\n    'Batch Similarity': batch_results\n})\n\nprint(\"\\nResults Comparison:\")\nprint(results_df)\nprint(f\"\\nPerformance Comparison:\")\nprint(f\"Individual processing time: {individual_time:.4f} seconds\")\nprint(f\"Batch processing time: {batch_time:.4f} seconds\")\nprint(f\"Speed improvement: {individual_time/batch_time:.2f}x\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conclusions\n\n1. **Effectiveness**: Sentence transformers effectively capture semantic similarities between text pairs\n2. **Performance**: Batch processing significantly improves efficiency for multiple comparisons\n3. **Scalability**: The approach is suitable for large-scale text analysis with proper batching\n\n## Recommendations\n\n1. Use batch processing for multiple text comparisons\n2. Consider caching embeddings for frequently compared texts\n3. Implement proper error handling for edge cases"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}